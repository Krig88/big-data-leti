{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d0109e-dca6-470b-adce-37d0392bf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79c21f-cada-4a26-8ca3-a7ff36ed2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "data = pd.read_csv(\"path_to_your_dataset.csv\")  # Путь к датасету\n",
    "# 1. Проверка на пропущенные значения\n",
    "print(data.isnull().sum())\n",
    "# 2. Обработка пропущенных значений\n",
    "# Применяем медиану для числовых столбцов, т.к. это не будет искажать данные\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# 3. Выявление и удаление выбросов (например, с помощью Z-оценки)\n",
    "z_scores = np.abs(stats.zscore(data_imputed.select_dtypes(include=np.number)))\n",
    "data_no_outliers = data_imputed[(z_scores < 3).all(axis=1)]  # Оставляем только строки без выбросов\n",
    "\n",
    "# 4. Кодирование категориальных признаков (если есть такие)\n",
    "# Предположим, что целевая переменная \"class\" является категориальной\n",
    "label_encoder = LabelEncoder()\n",
    "data_no_outliers['class'] = label_encoder.fit_transform(data_no_outliers['class'])\n",
    "\n",
    "# 5. Применение Isolation Forest для обнаружения аномалий и их удаления\n",
    "iso_forest = IsolationForest(contamination=0.05)  # Указываем уровень аномалий\n",
    "anomalies = iso_forest.fit_predict(data_no_outliers.drop('class', axis=1))\n",
    "\n",
    "# Удаляем аномальные записи\n",
    "data_cleaned = data_no_outliers[anomalies == 1]  # Оставляем только нормальные данные\n",
    "print(f\"После очистки осталось строк: {data_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93018dfe-46cb-456f-b664-47c12503d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Преобразуем целевую переменную для бинарной классификации\n",
    "data_cleaned['class_binary'] = data_cleaned['class'].apply(lambda x: 0 if x == 0 else 1)  # 0 - benign, 1 - malicious\n",
    "\n",
    "# 2. Разделение на обучающую и тестовую выборки\n",
    "X = data_cleaned.drop(['class', 'class_binary'], axis=1)  # Признаки\n",
    "y_binary = data_cleaned['class_binary']  # Целевая переменная\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Обучение модели XGBoost\n",
    "model_xgb = xgb.XGBClassifier(scale_pos_weight=1)  # Для балансировки классов\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# 4. Оценка модели\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "print(\"Точность модели XGBoost для бинарной классификации:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ea9b8-1a9a-4b7c-a771-8fffa6335a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_cleaned.drop(['class', 'class_binary'], axis=1)\n",
    "# 1. Преобразуем целевую переменную для мультиклассовой классификации\n",
    "y_multiclass = data_cleaned['class']  # Это переменная с 11 классами\n",
    "\n",
    "# 2. Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_multiclass, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Обучение модели XGBoost для мультиклассовой классификации\n",
    "model_xgb_multiclass = xgb.XGBClassifier(objective='multi:softmax', num_class=11)\n",
    "model_xgb_multiclass.fit(X_train, y_train)\n",
    "\n",
    "# 4. Оценка модели\n",
    "y_pred_multiclass = model_xgb_multiclass.predict(X_test)\n",
    "print(\"Точность модели XGBoost для мультиклассовой классификации:\", accuracy_score(y_test, y_pred_multiclass))\n",
    "print(classification_report(y_test, y_pred_multiclass))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8f0c8-c0a3-482e-82e9-69a280b0d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Используем данные только для \"benign\" (нормальные данные)\n",
    "benign_data = data_cleaned[data_cleaned['class_binary'] == 0].drop(['class', 'class_binary'], axis=1)\n",
    "\n",
    "# 2. Обучение модели Isolation Forest\n",
    "iso_forest_anomalies = IsolationForest(contamination=0.05)\n",
    "anomalies_benign = iso_forest_anomalies.fit_predict(benign_data)\n",
    "\n",
    "# 3. Определим аномалии на тестовом наборе (все данные)\n",
    "anomalies_all = iso_forest_anomalies.predict(X_test)\n",
    "\n",
    "# 4. Оценка\n",
    "print(\"Обнаружены аномалии в тестовом наборе:\", np.sum(anomalies_all == -1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
